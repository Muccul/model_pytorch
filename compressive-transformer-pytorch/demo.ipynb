{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mogrifier import Mogrifier\n",
    "\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "\n",
    "from compressive_transformer_pytorch import CompressiveTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompressiveTransformer(\n",
    "    num_tokens = 20000,\n",
    "    emb_dim = 128,                 # embedding dimensions, embedding factorization from Albert paper\n",
    "    dim = 512,\n",
    "    depth = 12,\n",
    "    seq_len = 1024,\n",
    "    mem_len = 1024,                # memory length\n",
    "    cmem_len = 1024 // 4,          # compressed memory buffer length\n",
    "    cmem_ratio = 4,                # compressed memory ratio, 4 was recommended in paper\n",
    "    reconstruction_loss_weight = 1,# weight to place on compressed memory reconstruction loss\n",
    "    attn_dropout = 0.1,            # dropout post-attention\n",
    "    ff_dropout = 0.1,              # dropout in feedforward\n",
    "    attn_layer_dropout = 0.1,      # dropout for attention layer output\n",
    "    gru_gated_residual = True,     # whether to gate the residual intersection, from 'Stabilizing Transformer for RL' paper\n",
    "    mogrify_gru = False,           # experimental feature that adds a mogrifier for the update and residual before gating by the GRU\n",
    "    memory_layers = range(6, 13),  # specify which layers to use long-range memory, from 'Do Transformers Need LR Memory' paper\n",
    "    one_kv_head = False,            # share one key/value head for all queries, from Shazeers 'One Write-Head is All You Need'\n",
    "    ff_glu = True                  # use GLU variant for feedforward\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompressiveTransformer(\n",
       "  (token_emb): Embedding(20000, 128)\n",
       "  (to_model_dim): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (to_logits): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=20000, bias=True)\n",
       "  )\n",
       "  (attn_layers): ModuleList(\n",
       "    (0): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (1): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (2): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (3): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (4): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (5): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (6): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (7): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (8): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (9): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (10): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (11): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): SelfAttention(\n",
       "          (compress_mem_fn): ConvCompress(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(4,))\n",
       "          )\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "  )\n",
       "  (ff_layers): ModuleList(\n",
       "    (0): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (1): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (2): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (3): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (4): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (5): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (6): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (7): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (8): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (9): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (10): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "    (11): GRUGating(\n",
       "      (fn): PreNorm(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): FeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(512, 512)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 20000])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randint(0, 256, (1, 2048))  # [b, 2n]\n",
    "masks = torch.ones_like(inputs).bool()   # [b, nd]\n",
    "\n",
    "segments = inputs.reshape(1, -1, 1024).transpose(0, 1)  # [b, 2, n] -> [2,b,n]\n",
    "masks = masks.reshape(1, -1, 1024).transpose(0, 1)   # [b, 2, n]  -> [2,b,n]\n",
    "\n",
    "\n",
    "# seg[0] [b, n]\n",
    "# logits [b,1024,d]    mem [7, b, 1024, 512]\n",
    "logits, memories, aux_loss = model(segments[0], mask = masks[0])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_mem[7, b, 256, 512]\n",
    "logits,  memories, aux_loss = model(segments[1], mask = masks[1], memories = memories)\n",
    "\n",
    "# memories is a named tuple that contains the memory (mem) and the compressed memory (cmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import isfunction\n",
    "\n",
    "def default(x, val):\n",
    "    if x is not None:\n",
    "        return x\n",
    "    return val if not isfunction(val) else val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem, cmem = memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 1, 1024, 512]), torch.Size([7, 1, 256, 512]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.shape, cmem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,16)\n",
    "b = 2\n",
    "d = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(2, 0))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_tensor(t):\n",
    "    length = t.shape[0]\n",
    "    for ind in range(length):\n",
    "        yield t[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7537, -0.8728, -1.2249,  0.0646],\n",
       "         [ 0.7961,  0.2608, -0.9098, -1.7165],\n",
       "         [ 0.7452, -1.1558,  1.6637, -1.4666]],\n",
       "\n",
       "        [[-0.9516,  2.1680, -1.0025,  0.8389],\n",
       "         [ 0.1069, -1.4778,  1.0530, -1.1011],\n",
       "         [ 0.0072,  0.6764, -0.2917, -1.2895]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.randn(2,3,4)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCompress(nn.Module):\n",
    "    def __init__(self, dim, ratio = 4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, ratio, stride = ratio)\n",
    "\n",
    "    def forward(self, mem):\n",
    "        mem = mem.transpose(1, 2)\n",
    "        compressed_mem = self.conv(mem)\n",
    "        return compressed_mem.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dim(t, dim, split_dims):\n",
    "    shape = list(t.shape)\n",
    "    num_dims = len(shape)\n",
    "    dim = (dim + num_dims) % num_dims\n",
    "    shape[dim:dim+1] = split_dims\n",
    "    return t.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 16, 32]),\n",
       " torch.Size([2, 4, 16, 32]),\n",
       " torch.Size([2, 4, 16, 32]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_h = 32\n",
    "h = 4\n",
    "merge_heads = lambda x: reshape_dim(x, -1, (-1, dim_h)).transpose(1, 2)\n",
    "\n",
    "\n",
    "q = k = v = torch.randn(2,16,128)\n",
    "q, k, v = map(merge_heads, (q, k, v))   # [b,n,d] -> [b,h,n,h_d]\n",
    "\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 16, 32]), torch.Size([2, 4, 16, 32]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, v = map(lambda x: x.expand(-1, h, -1, -1), (k, v))  # k,v:[b,h,len_cmem+mem+x,h_d]\n",
    "k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.randn(2,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.expand(2,3,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 4\n",
    "total_mem_len = 6\n",
    "mask = torch.ones(t, t + total_mem_len,).triu_(diagonal = 1 + total_mem_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_at_index(dim, index, t):\n",
    "    pre_slices = (slice(None),) * dim\n",
    "    l = (*pre_slices, slice(None, index))\n",
    "    r = (*pre_slices, slice(index, None))\n",
    "    return t[l], t[r]\n",
    "\n",
    "\n",
    "def queue_fifo(*args, length, dim=-2):\n",
    "    queue = torch.cat(args, dim=dim)\n",
    "    if length > 0:\n",
    "        return split_at_index(dim, -length, queue)\n",
    "\n",
    "    device = queue.device\n",
    "    shape = list(queue.shape)\n",
    "    shape[dim] = 0\n",
    "    return queue, torch.empty(shape, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCompress(nn.Module):\n",
    "    def __init__(self, dim, ratio = 4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, ratio, stride = ratio)\n",
    "\n",
    "    def forward(self, mem):\n",
    "        mem = mem.transpose(1, 2)\n",
    "        compressed_mem = self.conv(mem)\n",
    "        return compressed_mem.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cc = ConvCompress(dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = torch.randn(2, 16, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 64])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cc(mem).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice(- min(mem_len, self.mem_len) - self.seq_len, -self.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(5)  # indexes 0,1,2,3,4\n",
    "li[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(0, 6)  # indexes 9,7,5,3,1\n",
    "li[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(1, 10, 2)  # indexes 1,3,5,7,9\n",
    "li[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 7, 5, 3, 1]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(9, 0, -2)  # indexes 9,7,5,3,1\n",
    "li[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(-6, -1)  # indexes 9,7,5,3,1\n",
    "li[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,10,5)\n",
    "x1 = x.split(2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1():\n",
    "    for i in range(10):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fun1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ok\n",
      "5 ok\n",
      "6 ok\n",
      "7 ok\n",
      "8 ok\n",
      "9 ok\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i, 'ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   mem cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_to_max_patch_idx = namedtuple('mem_to_max_patch_idx', ['cur_idx', 'max_attach_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = mem_to_max_patch_idx(cur_idx=0, max_attach_idx=5)\n",
    "k.cur_idx, k.max_attach_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.Tensor(list(range(4*4))).reshape(4,4)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5,\n",
       " 1: 6,\n",
       " 2: 7,\n",
       " 3: 7,\n",
       " 4: 9,\n",
       " 5: 10,\n",
       " 6: 11,\n",
       " 7: 11,\n",
       " 8: 13,\n",
       " 9: 14,\n",
       " 10: 15,\n",
       " 11: 15,\n",
       " 12: 13,\n",
       " 13: 14,\n",
       " 14: 15,\n",
       " 15: 15}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_mapping = dict()  # mapping cur_idx: max_attach_idx\n",
    "mem_expand_size = 1\n",
    "patch_height = 4\n",
    "patch_width = 4\n",
    "for cur_patch_idx in range(4*4):\n",
    "    cur_row = cur_patch_idx // patch_width\n",
    "    cur_col = cur_patch_idx % patch_width\n",
    "    max_row = min(patch_height-1, cur_row+mem_expand_size)\n",
    "    max_col = min(patch_width-1, cur_col+mem_expand_size)\n",
    "    max_idx = max_row * patch_width + max_col\n",
    "    mem_mapping[cur_patch_idx] = max_idx\n",
    "    \n",
    "mem_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mem(mem_pool, mem_mapping, mem, cur_patch_idx):\n",
    "    # add new_mem\n",
    "    mem_pool[cur_patch_idx] = mem\n",
    "\n",
    "    # filter mem\n",
    "    del_idxs = []\n",
    "    for k in mem_pool.keys():\n",
    "        if mem_mapping[k] > cur_patch_idx:\n",
    "            continue\n",
    "        else:\n",
    "            del_idxs.append(k)\n",
    "    for del_idx in del_idxs:\n",
    "        del mem_pool[del_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur: 0\n",
      "{0: 'mem0'}\n",
      "****************\n",
      "cur: 1\n",
      "{0: 'mem0', 1: 'mem1'}\n",
      "****************\n",
      "cur: 2\n",
      "{0: 'mem0', 1: 'mem1', 2: 'mem2'}\n",
      "****************\n",
      "cur: 3\n",
      "{0: 'mem0', 1: 'mem1', 2: 'mem2', 3: 'mem3'}\n",
      "****************\n",
      "cur: 4\n",
      "{0: 'mem0', 1: 'mem1', 2: 'mem2', 3: 'mem3', 4: 'mem4'}\n",
      "****************\n",
      "cur: 5\n",
      "{1: 'mem1', 2: 'mem2', 3: 'mem3', 4: 'mem4', 5: 'mem5'}\n",
      "****************\n",
      "cur: 6\n",
      "{2: 'mem2', 3: 'mem3', 4: 'mem4', 5: 'mem5', 6: 'mem6'}\n",
      "****************\n",
      "cur: 7\n",
      "{4: 'mem4', 5: 'mem5', 6: 'mem6', 7: 'mem7'}\n",
      "****************\n",
      "cur: 8\n",
      "{4: 'mem4', 5: 'mem5', 6: 'mem6', 7: 'mem7', 8: 'mem8'}\n",
      "****************\n",
      "cur: 9\n",
      "{5: 'mem5', 6: 'mem6', 7: 'mem7', 8: 'mem8', 9: 'mem9'}\n",
      "****************\n",
      "cur: 10\n",
      "{6: 'mem6', 7: 'mem7', 8: 'mem8', 9: 'mem9', 10: 'mem10'}\n",
      "****************\n",
      "cur: 11\n",
      "{8: 'mem8', 9: 'mem9', 10: 'mem10', 11: 'mem11'}\n",
      "****************\n",
      "cur: 12\n",
      "{8: 'mem8', 9: 'mem9', 10: 'mem10', 11: 'mem11', 12: 'mem12'}\n",
      "****************\n",
      "cur: 13\n",
      "{9: 'mem9', 10: 'mem10', 11: 'mem11', 13: 'mem13'}\n",
      "****************\n",
      "cur: 14\n",
      "{10: 'mem10', 11: 'mem11', 14: 'mem14'}\n",
      "****************\n",
      "cur: 15\n",
      "{}\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "mem_pool_list = []\n",
    "mem_pool = dict()\n",
    "for i in range(16):\n",
    "    update_mem(mem_pool, mem_mapping, 'mem'+str(i), i)\n",
    "    \n",
    "    mem_pool_list.append(mem_pool.copy())\n",
    "    print('cur:', i)\n",
    "    print(mem_pool)\n",
    "    \n",
    "    \n",
    "    print('*'*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   concat mem+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mem_from_pool(mem_pool, cur_patch_idx, mem_expand_size=1, patch_height=4, patch_width=4):\n",
    "    cur_patch_row = cur_patch_idx // patch_width\n",
    "    cur_patch_col = cur_patch_idx % patch_width\n",
    "\n",
    "    rows = torch.arange(max(0, cur_patch_row - mem_expand_size), min(patch_height, cur_patch_row + 1))\n",
    "    cols = torch.arange(max(0, cur_patch_col - mem_expand_size), min(patch_width, cur_patch_col + mem_expand_size + 1))\n",
    "\n",
    "    coords_init = torch.stack(torch.meshgrid([rows, cols]), dim=-1).reshape(-1, 2)\n",
    "    coords_filtered = [coord for coord in coords_init if coord[0] < cur_patch_row or coord[1] < cur_patch_col]\n",
    "    mem_idxs = [int(coord[0] * patch_width + coord[1]) for coord in coords_filtered]\n",
    "\n",
    "    return [mem_pool[idx] for idx in mem_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'mem2', 3: 'mem3', 4: 'mem4', 5: 'mem5', 6: 'mem6'}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_pool_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mem1', 'mem2', 'mem3', 'mem5']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mem_from_pool(mem_pool_list[5], 6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_list = []\n",
    "for i in range(4*4):\n",
    "    mem = torch.full((2,2*2), i)\n",
    "    mem_list.append(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2, m3, m4 = mem_list[0],mem_list[1],mem_list[2],mem_list[4]\n",
    "ms = [m1,m2,m3,m4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mem_list[5]\n",
    "ms += [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.concat(ms, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rel pos emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pair-wise relative position index for each token inside the window\n",
    "window_size = (7,7)\n",
    "\n",
    "coords_h = torch.arange(window_size[0])\n",
    "coords_w = torch.arange(window_size[1])\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4, 4, 4],\n",
       "         [5, 5, 5, 5, 5, 5, 5],\n",
       "         [6, 6, 6, 6, 6, 6, 6]],\n",
       "\n",
       "        [[0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 1, 2, 3, 4, 5, 6]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 49]), tensor([1, 1]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "coords_flatten.shape, coords_flatten[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 49, 49]),\n",
       " tensor([[[ 0,  0,  0,  ..., -6, -6, -6],\n",
       "          [ 0,  0,  0,  ..., -6, -6, -6],\n",
       "          [ 0,  0,  0,  ..., -6, -6, -6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  0,  0,  0],\n",
       "          [ 6,  6,  6,  ...,  0,  0,  0],\n",
       "          [ 6,  6,  6,  ...,  0,  0,  0]],\n",
       " \n",
       "         [[ 0, -1, -2,  ..., -4, -5, -6],\n",
       "          [ 1,  0, -1,  ..., -3, -4, -5],\n",
       "          [ 2,  1,  0,  ..., -2, -3, -4],\n",
       "          ...,\n",
       "          [ 4,  3,  2,  ...,  0, -1, -2],\n",
       "          [ 5,  4,  3,  ...,  1,  0, -1],\n",
       "          [ 6,  5,  4,  ...,  2,  1,  0]]]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2, Wh*Ww, Wh*Ww\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  \n",
    "relative_coords.shape, relative_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wh*Ww, Wh*Ww, 2, [i,j,:]表示窗口内第i个patch相对于第j个patch的坐标\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 49, 2])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -2, -2, -2, -2, -2, -2, -2, -3, -3, -3, -3, -3, -3, -3, -4,\n",
       "        -4, -4, -4, -4, -4, -4, -5, -5, -5, -5, -5, -5, -5])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords[7,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1, -2, -3, -4, -5, -6,  0, -1, -2, -3, -4, -5, -6,  0, -1, -2, -3,\n",
       "        -4, -5, -6,  0, -1, -2, -3, -4, -5, -6,  0, -1, -2, -3, -4, -5, -6,  0,\n",
       "        -1, -2, -3, -4, -5, -6,  0, -1, -2, -3, -4, -5, -6])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords[7,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_coords[:, :, 0] += window_size[0] - 1  # shift to start from 0\n",
    "relative_coords[:, :, 1] += window_size[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4,\n",
       "        4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "        1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords[7,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4,\n",
       "        3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1,\n",
       "        0])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords[7,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([169, 4])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a parameter table of relative position bias  # shape : 2*Wh-1 * 2*Ww-1, nH\n",
    "num_heads = 4\n",
    "relative_position_bias_table = nn.Parameter(\n",
    "    torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)) \n",
    "relative_position_bias_table.shape  # 2*7-1=13  13*13=169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_coords[:, :, 0] *= 2 * window_size[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([91, 91, 91, 91, 91, 91, 91, 78, 78, 78, 78, 78, 78, 78, 65, 65, 65, 65,\n",
       "        65, 65, 65, 52, 52, 52, 52, 52, 52, 52, 39, 39, 39, 39, 39, 39, 39, 26,\n",
       "        26, 26, 26, 26, 26, 26, 13, 13, 13, 13, 13, 13, 13])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords[7,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 49, 2])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 49])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "relative_position_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 84,  83,  82,  ...,   2,   1,   0],\n",
       "        [ 85,  84,  83,  ...,   3,   2,   1],\n",
       "        [ 86,  85,  84,  ...,   4,   3,   2],\n",
       "        ...,\n",
       "        [166, 165, 164,  ...,  84,  83,  82],\n",
       "        [167, 166, 165,  ...,  85,  84,  83],\n",
       "        [168, 167, 166,  ...,  86,  85,  84]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 49, 4])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_bias = relative_position_bias_table[relative_position_index.view(-1)].view(\n",
    "    window_size[0] * window_size[1], window_size[0] * window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "relative_position_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 49, 49])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "relative_position_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
